{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjoh1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import numpy as np\n",
    "from flask import Flask, redirect, url_for, request, render_template\n",
    "#파일 업로드\n",
    "\n",
    "import glob\n",
    "#파일이름 보호\n",
    "from werkzeug.utils import secure_filename\n",
    "from gevent.pywsgi import WSGIServer\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "# Disable scientific notation for clarity\n",
    "model_transfer = models.resnet50(pretrained=True)\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "model_transfer.fc = nn.Linear(2048, 133, bias=True)\n",
    "fc_parameters = model_transfer.fc.parameters()\n",
    "for param in fc_parameters:\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_transfer.load_state_dict(torch.load('saved_models/model_transfer.pt'))\n",
    "\n",
    "data_dir = '/Users/bjoh1/python/capst/body/'\n",
    "train_dir = os.path.join(data_dir, 'train/')\n",
    "valid_dir = os.path.join(data_dir, 'valid/')\n",
    "test_dir = os.path.join(data_dir, 'test/')\n",
    "batch_size = 20\n",
    "num_workers = 0\n",
    "\n",
    "\n",
    "\n",
    "standard_normalization = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "data_transforms = {'train': transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     standard_normalization]),\n",
    "                   'val': transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     standard_normalization]),\n",
    "                   'test': transforms.Compose([transforms.Resize(size=(224,224)),\n",
    "                                     transforms.ToTensor(), \n",
    "                                     standard_normalization])\n",
    "                  }\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=data_transforms['val'])\n",
    "test_data = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=False)\n",
    "loaders_scratch = {\n",
    "    'train': train_loader,\n",
    "    'valid': valid_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "loaders_transfer = loaders_scratch.copy()\n",
    "\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in loaders_transfer['train'].dataset.classes]\n",
    "\n",
    "def load_input_image(img_path):    \n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    prediction_transform = transforms.Compose([transforms.Resize(size=(224, 224)),\n",
    "                                     transforms.ToTensor(), \n",
    "                                     standard_normalization])\n",
    "\n",
    "    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n",
    "    image = prediction_transform(image)[:3,:,:].unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "def body(model, class_names, img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    img = load_input_image(img_path)\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "    idx = torch.argmax(model(img))\n",
    "    return class_names[idx]\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/\",methods=['GET'])\n",
    "def index():\n",
    "\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route(\"/predict\",methods=['GET','POST'])\n",
    "def upload():\n",
    "    if request.method=='POST':\n",
    "        f=request.files['file']\n",
    "\n",
    "        basepath = os.path.dirname['file']\n",
    "        file_path = os.path.join(basepath,'uploads',secure_filename(f.filename))\n",
    "        f.save(file_path)\n",
    "\n",
    "        preds = body(model, class_names, file_path)\n",
    "       \n",
    "        \n",
    "        return preds\n",
    "\n",
    "    return None\n",
    "#메인 모듈로 실행될 때 플라스크 서버 구동\n",
    "if __name__ == \"__main__\":\n",
    "    #app.run(host='0.0.0.0' , debug=True)\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[[0.00005829 0.9999416  0.         0.         0.00000008 0.        ]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ec783d7405a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
